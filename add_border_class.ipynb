{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nrrd\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.color import gray2rgb, label2rgb\n",
    "from skimage.segmentation import find_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage.morphology import dilation, square\n",
    "import random\n",
    "\n",
    "def mark_boundaries_color(image, label_img, color=None, outline_color=None, mode='outer', background_label=0, dilation_size=1):\n",
    "    \"\"\"Return image with boundaries between labeled regions highlighted with consistent colors derived from labels.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image.\n",
    "    - label_img: Image with labeled regions.\n",
    "    - color: Ignored in this version.\n",
    "    - outline_color: If specified, use this color for the outline. Otherwise, use the same as boundary.\n",
    "    - mode: Choose 'inner', 'outer', or 'thick' to define boundary type.\n",
    "    - background_label: Label to be treated as the background.\n",
    "    - dilation_size: Size of the dilation square for the boundaries.\n",
    "\n",
    "    Returns:\n",
    "    - Image with boundaries highlighted.\n",
    "    \"\"\"\n",
    "    # Ensure input image is in float and has three channels\n",
    "    float_dtype = np.float32  # Use float32 for efficiency\n",
    "    marked = img_as_float(image, force_copy=True).astype(float_dtype, copy=False)\n",
    "    if marked.ndim == 2:\n",
    "        marked = gray2rgb(marked)\n",
    "\n",
    "    # Create a color map normalized by the number of unique labels\n",
    "    unique_labels = np.unique(label_img)\n",
    "    color_map = plt.get_cmap('nipy_spectral')  # You can change 'nipy_spectral' to any other colormap\n",
    "\n",
    "    # Find boundaries and apply colors\n",
    "    boundaries = find_boundaries(label_img, mode=mode, background=background_label)\n",
    "    for label in unique_labels:\n",
    "        if label == background_label:\n",
    "            continue\n",
    "        # Normalize label value to the range of the colormap\n",
    "        normalized_color = color_map(label / np.max(unique_labels))[:3]  # Get RGB values only\n",
    "        label_boundaries = find_boundaries(label_img == label, mode=mode)\n",
    "        label_boundaries = dilation(label_boundaries, square(dilation_size))\n",
    "        marked[label_boundaries] = normalized_color\n",
    "        if outline_color is not None:\n",
    "            outlines = dilation(label_boundaries, square(dilation_size + 1))\n",
    "            marked[outlines] = outline_color\n",
    "        else:\n",
    "            marked[label_boundaries] = normalized_color\n",
    "\n",
    "    return marked\n",
    "\n",
    "\n",
    "def consistent_color(label):\n",
    "    \"\"\"Generate a consistent color for a given label using a hash function.\"\"\"\n",
    "    random.seed(hash(label))\n",
    "    return [random.random() for _ in range(3)]\n",
    "\n",
    "def mark_boundaries_multicolor(image, label_img, color=None, outline_color=None, mode='outer', background_label=0, dilation_size=1):\n",
    "    \"\"\"Return image with boundaries between labeled regions highlighted with consistent colors.\n",
    "\n",
    "    Parameters are the same as in the original function but color is ignored if provided.\n",
    "    \"\"\"\n",
    "    # Ensure input image is in float and has three channels\n",
    "    float_dtype = np.float32  # Use float32 for efficiency\n",
    "    marked = img_as_float(image, force_copy=True).astype(float_dtype, copy=False)\n",
    "    if marked.ndim == 2:\n",
    "        marked = gray2rgb(marked)\n",
    "\n",
    "    # Generate consistent colors for each unique label in label_img\n",
    "    unique_labels = np.unique(label_img)\n",
    "    color_map = {label: consistent_color(label) for label in unique_labels if label != background_label}\n",
    "\n",
    "    # Find boundaries and apply colors\n",
    "    boundaries = find_boundaries(label_img, mode=mode, background=background_label)\n",
    "    for label, color in color_map.items():\n",
    "        label_boundaries = find_boundaries(label_img == label, mode=mode)\n",
    "        label_boundaries = dilation(label_boundaries, square(dilation_size))\n",
    "        if outline_color is not None:\n",
    "            outlines = dilation(label_boundaries, square(dilation_size))\n",
    "            marked[outlines] = outline_color\n",
    "        marked[label_boundaries] = color\n",
    "\n",
    "    return marked\n",
    "\n",
    "def plot_segmentation_results(test_slice, segmentation):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Show marked boundary image\n",
    "    axes[0].imshow(mark_boundaries(test_slice, np.array(segmentation)))\n",
    "    axes[0].set_title(\"Marked Boundary\")\n",
    "\n",
    "    # Show unmarked boundary image\n",
    "    axes[1].imshow(test_slice, cmap='gray')\n",
    "    axes[1].set_title(\"Unmarked Boundary\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nrrd\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_dilation, binary_closing\n",
    "\n",
    "def process_nrrd_files(root_dir):\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        if os.path.basename(subdir) == 'original_labels':\n",
    "            # Determine the corresponding 'label' directory\n",
    "            label_dir = os.path.join(os.path.dirname(subdir), 'label')\n",
    "            os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "            for file in files:\n",
    "                if file.endswith('.nrrd'):\n",
    "                    nrrd_path = os.path.join(subdir, file)\n",
    "                    data, header = nrrd.read(nrrd_path)\n",
    "                    \n",
    "                    unique_values = np.unique(data)\n",
    "                    unique_values = unique_values[unique_values != 0]  # Ignore background\n",
    "                    \n",
    "                    # Create an empty array for the result\n",
    "                    result = np.zeros_like(data)\n",
    "                    \n",
    "                    for value in unique_values:\n",
    "                        structure_mask = data == value\n",
    "                        \n",
    "                        # Fill small holes in the structure\n",
    "                        closed_structure = structure_mask  # Keeping this as is\n",
    "                        \n",
    "                        # Dilate the closed structure\n",
    "                        dilated_mask = binary_dilation(closed_structure, iterations=3)\n",
    "                        \n",
    "                        # Assign the border class and foreground class\n",
    "                        border_class = dilated_mask & ~closed_structure\n",
    "                        result[~border_class & dilated_mask] = 2  # Foreground class\n",
    "                        result[border_class] = 1  # Border class\n",
    "                    \n",
    "                    # Save the processed array back to an .nrrd file\n",
    "                    output_path = os.path.join(label_dir, f\"tri_class_{file}\")\n",
    "                    nrrd.write(output_path, result, header)\n",
    "                    print(f\"Processed and saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: /home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/val/label/tri_class_layers_1.nrrd\n"
     ]
    }
   ],
   "source": [
    "root_directory = '/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/val'\n",
    "process_nrrd_files(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f999f5596144a45af723f790d9bb0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_index', max=255), IntSlider(value=0, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_slice(slice_index, axis=0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "pred = nrrd.read('/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/val/label/tri_class_layers_1.nrrd')[0]\n",
    "pred = nrrd.read('/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/val/raw/layers_1.nrrd')[0]\n",
    "#show final clipped instance segmentation\n",
    "def plot_slice(slice_index, axis=0):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if axis == 1:\n",
    "        plt.imshow(pred[:,slice_index,:])\n",
    "    elif axis == 2:\n",
    "        plt.imshow(pred[:,:,slice_index])\n",
    "    else:\n",
    "        plt.imshow(pred[slice_index,:,:], cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Slice {slice_index}')\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_slice, slice_index=IntSlider(min=0, max=pred.shape[0]-1, step=1, value=0), axis=IntSlider(min=0, max=2, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee2784dea354ae183abc43cde4aca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_index', max=255), IntSlider(value=0, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_slice(slice_index, axis=0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "pred = nrrd.read('/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/test/label/tri_class_layers_1.nrrd')[0]\n",
    "foreground = pred == 2\n",
    "fg, num_features = scipy.ndimage.label(foreground)\n",
    "# pred = nrrd.read('/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/test/original_labels/layers_1.nrrd')[0]\n",
    "#show final clipped instance segmentation\n",
    "def plot_slice(slice_index, axis=0):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if axis == 1:\n",
    "        plt.imshow(fg[:,slice_index,:])\n",
    "    elif axis == 2:\n",
    "        plt.imshow(fg[:,:,slice_index])\n",
    "    else:\n",
    "        plt.imshow(fg[slice_index,:,:])\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Slice {slice_index}')\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_slice, slice_index=IntSlider(min=0, max=pred.shape[0]-1, step=1, value=0), axis=IntSlider(min=0, max=2, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "def label_foreground_structures(input_array, min_size=100000): #use aggressize min_size to remove small structures, then decent overlap stride to get ones that are erronously cut off on the edges\n",
    "    # Find connected components in the foreground (value 2)\n",
    "    foreground = (input_array == 2)\n",
    "    \n",
    "    # Label connected components\n",
    "    labeled_array, num_features = scipy.ndimage.label(foreground)\n",
    "    \n",
    "    # Measure the size of each connected component\n",
    "    component_sizes = np.bincount(labeled_array.ravel())\n",
    "    \n",
    "    # Create a mask for components larger than the minimum size\n",
    "    large_components = component_sizes >= min_size\n",
    "    \n",
    "    # Ensure background is not considered a component\n",
    "    large_components[0] = False\n",
    "    \n",
    "    # Create a filtered array to hold only large components\n",
    "    filtered_array = labeled_array.copy()\n",
    "    \n",
    "    # Set small components to 0 (background)\n",
    "    filtered_array[~large_components[labeled_array]] = 0\n",
    "    \n",
    "    print(f\"Number of connected foreground structures before filtering: {num_features}\")\n",
    "    print(f\"Number of connected foreground structures after filtering: {np.max(filtered_array)}\")\n",
    "    \n",
    "    return filtered_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connected foreground structures before filtering: 144\n",
      "Number of connected foreground structures after filtering: 13\n",
      "[ 0  1  2  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "labeled_arr = label_foreground_structures(pred)\n",
    "img_path = '/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/test/raw/layers_1.nrrd'\n",
    "img, _ = nrrd.read(img_path)\n",
    "gt_label = nrrd.read('/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/test/original_labels/layers_1.nrrd')[0]\n",
    "print(np.unique(gt_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fade88dbaef485bafc80d8b7e77b595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_index', max=255), IntSlider(value=0, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_slice(slice_index, axis=0)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_slice(slice_index, axis=0):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if axis == 1:\n",
    "        plt.imshow(mark_boundaries_color(img[:,slice_index,:], labeled_arr[:,slice_index,:]))\n",
    "    elif axis == 2:\n",
    "        plt.imshow(mark_boundaries_color(img[:,:,slice_index], labeled_arr[:,:,slice_index]))\n",
    "    else:\n",
    "        plt.imshow(mark_boundaries_color(img[slice_index,:,:], labeled_arr[slice_index,:,:]))\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Slice {slice_index}')\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_slice, slice_index=IntSlider(min=0, max=pred.shape[0]-1, step=1, value=0), axis=IntSlider(min=0, max=2, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af801a43e66b4729b17ff41f021d3a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_index', max=255), IntSlider(value=0, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_slice(slice_index, axis=0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "pred2 = nrrd.read('/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/test/original_labels/layers_1.nrrd')[0]\n",
    "#show final clipped instance segmentation\n",
    "def plot_slice(slice_index, axis=0):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if axis == 1:\n",
    "        plt.imshow(pred2[:,slice_index,:])\n",
    "    elif axis == 2:\n",
    "        plt.imshow(pred2[:,:,slice_index])\n",
    "    else:\n",
    "        plt.imshow(pred2[slice_index,:,:])\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Slice {slice_index}')\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_slice, slice_index=IntSlider(min=0, max=pred2.shape[0]-1, step=1, value=0), axis=IntSlider(min=0, max=2, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import nrrd\n",
    "import numpy as np\n",
    "\n",
    "def create_hdf5_files(raw_dir, label_dir, output_dir, weight_dir=None):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for raw_filename in os.listdir(raw_dir):\n",
    "        if raw_filename.endswith('.nrrd'):\n",
    "            # Construct full file paths for raw and label\n",
    "            raw_path = os.path.join(raw_dir, raw_filename)\n",
    "            label_filename = f\"tri_class_{raw_filename}\"\n",
    "            label_path = os.path.join(label_dir, label_filename)\n",
    "\n",
    "            print(f\"Processing: {raw_filename} and {label_filename}\")\n",
    "            \n",
    "            if not os.path.exists(label_path):\n",
    "                label_filename = \"tri_class_\"+'_'.join(raw_filename.split('_')[:-1])+'_label.nrrd'\n",
    "                print(f\"Label file not found for {raw_filename}, trying {label_filename}\")\n",
    "                label_path = os.path.join(label_dir, label_filename)\n",
    "            if not os.path.exists(label_path):\n",
    "                print(f\"Label file not found for {raw_filename}, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Read raw and label data\n",
    "            raw_data, raw_header = nrrd.read(raw_path)\n",
    "            label_data, label_header = nrrd.read(label_path)\n",
    "            \n",
    "            # Optionally read weight data\n",
    "            weight_data = None\n",
    "            if weight_dir:\n",
    "                weight_path = os.path.join(weight_dir, label_filename)\n",
    "                if os.path.exists(weight_path):\n",
    "                    weight_data, weight_header = nrrd.read(weight_path)\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            raw_data = np.asarray(raw_data, dtype=np.float32)\n",
    "            label_data = np.asarray(label_data, dtype=np.uint8)\n",
    "            if weight_data is not None:\n",
    "                weight_data = np.asarray(weight_data, dtype=np.float32)\n",
    "            \n",
    "            # Construct output file path\n",
    "            output_filename = os.path.splitext(raw_filename)[0] + '.h5'\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            # Create HDF5 file\n",
    "            with h5py.File(output_path, 'w') as hdf5_file:\n",
    "                hdf5_file.create_dataset('raw', data=raw_data, dtype='float32')\n",
    "                hdf5_file.create_dataset('label', data=label_data, dtype='uint8')\n",
    "                if weight_data is not None:\n",
    "                    hdf5_file.create_dataset('weight', data=weight_data, dtype='float32')\n",
    "            \n",
    "            print(f\"Processed and saved {raw_filename} and {label_filename} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dir = 'test'\n",
    "raw_directory = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/raw'\n",
    "label_directory = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/label'\n",
    "output_hdf5_path = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/dataset'\n",
    "create_hdf5_files(raw_directory, label_directory, output_hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: layers_1.nrrd and tri_class_layers_1.nrrd\n",
      "Processed and saved layers_1.nrrd and tri_class_layers_1.nrrd to /home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/val/dataset/layers_1.h5\n"
     ]
    }
   ],
   "source": [
    "sub_dir = 'val'\n",
    "raw_directory = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/raw'\n",
    "label_directory = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/label'\n",
    "output_hdf5_path = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/dataset'\n",
    "create_hdf5_files(raw_directory, label_directory, output_hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 3350_4000_8450_xyz_256_res1_s4_raw.nrrd and tri_class_3350_4000_8450_xyz_256_res1_s4_raw.nrrd\n",
      "Label file not found for 3350_4000_8450_xyz_256_res1_s4_raw.nrrd, trying tri_class_3350_4000_8450_xyz_256_res1_s4_label.nrrd\n",
      "Processed and saved 3350_4000_8450_xyz_256_res1_s4_raw.nrrd and tri_class_3350_4000_8450_xyz_256_res1_s4_label.nrrd to /home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/train/dataset/3350_4000_8450_xyz_256_res1_s4_raw.h5\n",
      "Processing: layers_1.nrrd and tri_class_layers_1.nrrd\n",
      "Processed and saved layers_1.nrrd and tri_class_layers_1.nrrd to /home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/train/dataset/layers_1.h5\n"
     ]
    }
   ],
   "source": [
    "sub_dir = 'train'\n",
    "raw_directory = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/raw'\n",
    "label_directory = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/label'\n",
    "output_hdf5_path = f'/home/james/Documents/VS/pytorch-3dunet-instanceSeg/data/Vesuvius/{sub_dir}/dataset'\n",
    "create_hdf5_files(raw_directory, label_directory, output_hdf5_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Normals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
